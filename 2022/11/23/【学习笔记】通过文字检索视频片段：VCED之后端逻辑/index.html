<!DOCTYPE html>
<html lang="zh-CN">





<head><!-- hexo injector head_begin start --><!--Google tag(gtag.js)--><script async src="https://www.googletagmanager.com/gtag/js?id=G-6Q0B58X6TL"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date());gtag("config","G-6Q0B58X6TL");</script><!-- hexo injector head_begin end -->
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="Superlova">
  <meta name="keywords" content="">
  <title>【学习笔记】通过文字检索视频片段：VCED之后端逻辑 - Superlova</title>
  <meta name="google-site-verification" content="CPvPw8mUZw65A1ALJ8uRzsYECq4mXgE4_eCq40VIhPM" />
  <link  rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.12.1/css/all.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/mdbootstrap/4.13.0/css/mdb.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css" />

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link  rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css" />

<link  rel="stylesheet" href="/css/main.css" />


  <link defer rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />


<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="Superlova" type="application/atom+xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Superlova</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">首页</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">归档</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/cover_2.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <p class="mt-3 post-meta">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>
                  星期三, 十一月 23日 2022, 9:49 晚上
                </p>
              

              <p class="mt-1">
                
                  
                  <span class="post-meta">
                    <i class="far fa-chart-bar"></i>
                    1.6k 字
                  </span>
                

                
                  
                  <span class="post-meta">
                      <i class="far fa-clock"></i>
                      8 分钟
                  </span>
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  <span id="busuanzi_container_page_pv" class="post-meta" style="display: none">
                    <i class="far fa-eye" aria-hidden="true"></i>
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>
                
              </p>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5 z-depth-3" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p
                class="note note-warning">本文最后更新于：星期四, 十一月 24日 2022, 1:50 凌晨</p>
            
            <div class="markdown-body">
              <p>本篇文章是跨模态检索工具 VCED 介绍的第五篇，前面介绍了前端部分，本篇来研究后端部分。</p>
<!--more--->
<h2 id="一、概览"><a href="#一、概览" class="headerlink" title="一、概览"></a>一、概览</h2><p>项目后端共由四个文件组成，其中 VideoLoader 负责对上传的视频进行关键帧提取，CustomClipText 负责将上传的图片转换为向量数据，CustomClipImage 负责将提取的关键帧转换为向量数据，SimpleIndexer 负责向量数据的检索。</p>
<ul>
<li>VideoLoader</li>
<li>CustomClipText</li>
<li>CustomClipImage</li>
<li>SimpleIndexer</li>
</ul>
<h2 id="二、VideoLoader"><a href="#二、VideoLoader" class="headerlink" title="二、VideoLoader"></a>二、VideoLoader</h2><p>VideoLoader 继承自 Executor，在整个后端中执行抽帧操作。</p>
<p>这里简单介绍下核心代码：</p>
<pre><code class="lang-py"># 将提取函数注册在路由的 /extract 里
@requests(on=&#39;/extract&#39;)
def extract(self, docs: DocumentArray, parameters: Dict, **kwargs):
    &quot;&quot;&quot;
    Load the video from the Document.uri, extract frames and audio. The extracted data are stored in chunks.

    :param docs: the input Documents with either the video file name or data URI in the `uri` field
    :param parameters: A dictionary that contains parameters to control
        extractions and overrides default values.
    Possible values are `ffmpeg_audio_args`, `ffmpeg_video_args`, `librosa_load_args`. Check out more description in the `__init__()`.
    For example, `parameters=&#123;&#39;ffmpeg_video_args&#39;: &#123;&#39;s&#39;: &#39;512x320&#39;&#125;`.
    &quot;&quot;&quot;
    for doc in docs:
        # 每个 doc 对应一段视频链接，先把它封装成一个对象
        with tempfile.TemporaryDirectory() as tmpdir:
            source_fn = (
                self._save_uri_to_tmp_file(doc.uri, tmpdir)
                if self._is_datauri(doc.uri)
                else doc.uri
            )

            # extract all the frames video
            if &#39;image&#39; in self._modality:
                ffmpeg_video_args = deepcopy(self._ffmpeg_video_args)
                ffmpeg_video_args.update(parameters.get(&#39;ffmpeg_video_args&#39;, &#123;&#125;))
                # 调用内部函数，把视频帧抽出来变成 tensor
                frame_tensors = self._convert_video_uri_to_frames(
                    source_fn, doc.uri, ffmpeg_video_args
                )
                for idx, frame_tensor in enumerate(frame_tensors):
                    self.logger.debug(f&#39;frame: &#123;idx&#125;&#39;)
                    chunk = Document(modality=&#39;image&#39;)
                    # chunk.blob = frame_tensor
                    max_size = 240
                    img = Image.fromarray(frame_tensor)
                    if img.size[0] &gt; img.size[1]:
                        width = max_size
                        height = math.ceil(max_size / img.size[0] * img.size[1])
                    else:
                        height = max_size
                        width = math.ceil(max_size / img.size[1] * img.size[0])
                    img = img.resize((width, height))
                    chunk.tensor = np.asarray(img).astype(&#39;uint8&#39;)
                    print(chunk.tensor.shape)
                    # chunk.tensor = np.array(frame_tensor).astype(&#39;uint8&#39;)
                    chunk.location = (np.uint32(idx),)
                    chunk.tags[&#39;timestamp&#39;] = idx / self._frame_fps
                    if self._copy_uri:
                        chunk.tags[&#39;video_uri&#39;] = doc.uri
                    # 到这里视频帧都被存在 doc 的 chunk 里了。
                    doc.chunks.append(chunk)
</code></pre>
<p>VideoLoader 的子函数中，有专门负责提取视频帧的参数，来得到视频分辨率的；有获取音频采样率等信息的；也有获取字幕文本的（即尝试查找 srt字幕文件）。</p>
<h2 id="三、CustomClipText"><a href="#三、CustomClipText" class="headerlink" title="三、CustomClipText"></a>三、CustomClipText</h2><p>该模块负责调用 CLIP 来实现把文本变成 embeddings 的功能。它的关键算法是：</p>
<pre><code class="lang-py">def encode(self, docs: DocumentArray, parameters: Dict, **kwargs):
    print(&#39;clip_text encode&#39;)
    for docs_batch in DocumentArray(
        filter(
            lambda x: bool(x.text),
            docs[parameters.get(&#39;traversal_paths&#39;, self.traversal_paths)],
        )
    ).batch(batch_size=parameters.get(&#39;batch_size&#39;, self.batch_size)) :

        text_batch = docs_batch.texts
        t1 = time.time()
        with torch.inference_mode():
            input_tokens = [self.model.encode_text(clip.tokenize([t, &quot;unknown&quot;]).to(self.device)) for t in text_batch] # self._generate_input_tokens(text_batch)
            embeddings = input_tokens # self.model.get_text_features(**input_tokens).cpu().numpy()
            for doc, embedding in zip(docs_batch, embeddings):
                doc.embedding = embedding
                # doc.embedding = np.array(embedding).astype(&#39;float32&#39;)[0]
        t2 = time.time()
        print(&quot;encode text cost:&quot;, t2 - t1)
        print(t1)
        print(t2)
</code></pre>
<p>你可以看到，它实际上就是调用了一个模型，并对数据进行了预处理，最后对文本数据进行编码，以 DocumentArray 形式存储，便于后续传值。</p>
<h2 id="四、CustomClipImage"><a href="#四、CustomClipImage" class="headerlink" title="四、CustomClipImage"></a>四、CustomClipImage</h2><p>与 CustomClipText 类似，通过 CLIP 模型把图片变成 Embedding。只要有 CLIP 模型，对数据进行与处理后即可得到它的 Embedding。</p>
<pre><code class="lang-py">def encode(self, docs: DocumentArray, parameters: dict, **kwargs):
    t1 = time.time()
    print(&#39;clip_image encode&#39;, t1)
    document_batches_generator =  DocumentArray(
        filter(
            lambda x: x is not None,
            docs[parameters.get(&#39;traversal_paths&#39;, self.traversal_paths)],
        )
    ).batch(batch_size=parameters.get(&#39;batch_size&#39;, self.batch_size))
    with torch.inference_mode():
        for batch_docs in document_batches_generator:
            print(&#39;in for&#39;)
            for d in batch_docs:
                print(&#39;in clip image d.uri&#39;, d.uri, len(d.chunks))
                # tensor = self._generate_input_features(tensors_batch)
                tensors_batch = []
                for c in d.chunks:
                    if (c.modality == &#39;image&#39;):
                        image_embedding = self.model.encode_image(self.preprocessor(Image.fromarray(c.tensor)).unsqueeze(0).to(self.device))
                        # tensors_batch.append(image_embedding)
                        tensors_batch.append(np.array(image_embedding).astype(&#39;float32&#39;))
                embedding = tensors_batch
                d.embedding = embedding
    t2 = time.time()
    print(&#39;clip_image encode end&#39;, t2 - t1, t2)
</code></pre>
<p>注意这里也将embedding 编码成了 DocArray形式进行存储。</p>
<h2 id="五、SimpleIndexer"><a href="#五、SimpleIndexer" class="headerlink" title="五、SimpleIndexer"></a>五、SimpleIndexer</h2><p>这里实现了关键的检索功能，首先需要将所有资源转化为他们的 Embedding（即 DocArray），然后使用向量相似度比较的方式进行检索。检索的代码如下：</p>
<pre><code class="lang-py">    def search(
        self,
        docs: &#39;DocumentArray&#39;,
        parameters: Optional[Dict] = None,
        **kwargs,
    ):
        &quot;&quot;&quot;Perform a vector similarity search and retrieve the full Document match

        :param docs: the Documents to search with
        :param parameters: the runtime arguments to `DocumentArray`&#39;s match
        function. They overwrite the original match_args arguments.
        &quot;&quot;&quot;
        match_args = (
            &#123;**self._match_args, **parameters&#125;
            if parameters is not None
            else self._match_args
        )

        traversal_right = parameters.get(
            &#39;traversal_right&#39;, self.default_traversal_right
        )
        traversal_left = parameters.get(&#39;traversal_left&#39;, self.default_traversal_left)
        match_args = SimpleIndexer._filter_match_params(docs, match_args)
        # print(&#39;in indexer&#39;,docs[traversal_left].embeddings.shape, self._index[traversal_right])
        texts: DocumentArray = docs[traversal_left]
        stored_docs: DocumentArray = self._index[traversal_right]

        doc_ids = parameters.get(&quot;doc_ids&quot;)
        t1 = time.time()
        with torch.inference_mode():
            t1_00 = time.time()
            for text in texts:
                result = []
                text_features = text.embedding
                text.embedding = None
                for sd in stored_docs:
                    if doc_ids is not None and sd.uri not in doc_ids:
                        continue
                    images_features = sd.embedding
                    print(&#39;images len&#39;,len(images_features))
                    t1_0 = time.time()
                    tensor_images_features = [Tensor(image_features) for image_features in images_features]
                    t1_1 = time.time()
                    for i, image_features in enumerate(tensor_images_features):
                        tensor = image_features
                        probs = self.score(tensor, text_features)
                        result.append(&#123;
                            &quot;score&quot;: probs[0][0],
                            &quot;index&quot;: i,
                            &quot;uri&quot;: sd.uri,
                            &quot;id&quot;: sd.id
                        &#125;)
                    t1_2 = time.time()
                    print(&quot;tensor cost:&quot;, t1_1 - t1_0)
                    print(&quot;part score cost:&quot;, t1_2 - t1_1)
                    print(t1_0)
                    print(t1_1)
                    print(t1_2)
                t2 = time.time()
                print(&#39;score cost:&#39;, t2 - t1)
                # print(parameters, type(parameters.get(&quot;thod&quot;)))
                index_list = self.getMultiRange(result,0.1 if parameters.get(&quot;thod&quot;) is None else parameters.get(&#39;thod&#39;), parameters.get(&quot;maxCount&quot;))
                t3 = time.time()
                print(&#39;range cost:&#39;, t3 - t2)
                print(t1)
                print(t1_00)
                print(t2)
                print(t3)
                # print(index_list)
                docArr = DocumentArray.empty(len(index_list))
                for i, doc in enumerate(docArr):
                    doc.tags[&quot;leftIndex&quot;] = index_list[i][&quot;leftIndex&quot;]
                    doc.tags[&quot;rightIndex&quot;] = index_list[i][&quot;rightIndex&quot;]
                    # print(index_list[i])
                    doc.tags[&quot;maxImageScore&quot;] = float(index_list[i][&quot;maxImage&quot;][&quot;score&quot;])
                    doc.tags[&quot;uri&quot;] = index_list[i][&quot;maxImage&quot;][&quot;uri&quot;]
                    doc.tags[&quot;maxIndex&quot;] = index_list[i][&quot;maxImage&quot;][&quot;index&quot;]
                # print(docArr)
                text.matches = docArr
</code></pre>
<p>对于每段匹配的视频帧，还会在最终有一个打分排序的操作。打分的过程其实就是对特征进行标准化，按照余弦相似度计算，最终通过softmax模型得出probability。实际代码如下：</p>
<pre><code class="lang-py">    def score(self, image_features, text_features):

        logit_scale = self.model.logit_scale.exp()
        # normalized features
        image_features = image_features / image_features.norm(dim=1, keepdim=True)
        text_features = text_features / text_features.norm(dim=1, keepdim=True)

        # cosine similarity as logits

        logits_per_image = logit_scale * image_features @ text_features.t()
        probs = logits_per_image.softmax(dim=-1).cpu().detach().numpy()

        # print(&quot; img Label probs:&quot;, probs)
        return probs
</code></pre>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总的来看 VCED 的后端部分不算复杂，只是忠实地使用了 Jina 提供的框架，将多模态数据抽象为 Document 后利用 Jina 提供的 api 进行处理继承 Executor 类，然后自定义自己的操作。</p>
<p>如果想要实现自己的 Executor，也可以类比上面提到的模块来继承一个；不过多数用户可以想到的功能都已经被上传到Jina Hub上，VideoLoader的主体也可以在hub中进行访问，可以直接调用封装好的Executor，实现自己的功能模块。</p>

            </div>
            <hr>
            <div>
              <p>
                
                  <span>
                <i class="iconfont icon-inbox"></i>
                    
                      <a class="hover-with-bg" href="/categories/notes/">notes</a>
                      &nbsp;
                    
                  </span>&nbsp;&nbsp;
                
                
                  <span>
                <i class="iconfont icon-tag"></i>
                    
                      <a class="hover-with-bg" href="/tags/VCED/">VCED</a>
                    
                      <a class="hover-with-bg" href="/tags/multimodal/">multimodal</a>
                    
                  </span>
                
              </p>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <script defer src="https://utteranc.es/client.js"
          repo="superlova / superlova.github.io"
          issue-term="pathname"
  
          label="utterances"
    
          theme="github-light"
          crossorigin="anonymous"
  >
  </script>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc-start"></div>
<div id="toc">
  <p class="h5"><i class="far fa-list-alt"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
<div>
  <span id="timeDate">载入天数...</span>
  <span id="times">载入时分秒...</span>
  <script>
  var now = new Date();
  function createtime(){
      var grt= new Date("02/14/2017 00:00:00");//此处修改你的建站时间或者网站上线时间
      now.setTime(now.getTime()+250);
      days = (now - grt ) / 1000 / 60 / 60 / 24;
      dnum = Math.floor(days);
      hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum);
      hnum = Math.floor(hours);
      if(String(hnum).length ==1 ){
          hnum = "0" + hnum;
      }
      minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
      mnum = Math.floor(minutes);
      if(String(mnum).length ==1 ){
                mnum = "0" + mnum;
      }
      seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
      snum = Math.round(seconds);
      if(String(snum).length ==1 ){
                snum = "0" + snum;
      }
      document.getElementById("timeDate").innerHTML = "本站安全运行&nbsp"+dnum+"&nbsp天";
      document.getElementById("times").innerHTML = hnum + "&nbsp小时&nbsp" + mnum + "&nbsp分&nbsp" + snum + "&nbsp秒";
  }
  setInterval("createtime()",250);
  </script>
</div>

<p id="hitokoto">:D 获取中...</p>
<script>
  fetch('https://v1.hitokoto.cn')
    .then(response => response.json())
    .then(data => {
      const hitokoto = document.getElementById('hitokoto')
      hitokoto.innerText = data.hitokoto
      })
      .catch(console.error)
</script>

  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    </div>
    
  <div>
    
      <!-- 不蒜子统计PV -->
      
      <span id="busuanzi_container_site_pv" style="display: none">
      总访问量 <span id="busuanzi_value_site_pv"></span> 次
    </span>
    
    
      <!-- 不蒜子统计UV -->
      
      <span id="busuanzi_container_site_uv" style="display: none">
      总访客数 <span id="busuanzi_value_site_uv"></span> 人
    </span>
    
  </div>


    

    
  </div>
</footer>



<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/popper.js/1.16.1/umd/popper.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="https://cdn.staticfile.org/mdbootstrap/4.13.0/js/mdb.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.10.0/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var navHeight = $('#navbar').height();
      var post = $('#post');
      var toc = $('#toc');
      var tocLimMax = post.offset().top + post.height() - navHeight;

      $(window).scroll(function () {
        var tocLimMin = $('#toc-start').offset().top - navHeight;
        var scroH = document.body.scrollTop + document.documentElement.scrollTop;

        if (tocLimMin <= scroH && scroH <= tocLimMax) {
          toc.css({
            'display': 'block',
            'position': 'fixed',
            'top': navHeight,
          });
        } else if (scroH <= tocLimMin) {
          toc.css({
            'position': '',
            'top': '',
          });
        } else if (scroH > tocLimMax) {
          toc.css('display', 'none');
        }
      });
      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        scrollSmooth: true,
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc > p').css('visibility', 'visible');
      }
      var offset = $('#board-ctn').css('margin-right')
      $('#toc-ctn').css({
        'right': offset
      })
    });
  </script>







  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




<!-- Plugins -->


  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?1040bcc5d25d5f4a9cb5e9855eb2c6db";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  



  <script  src="https://cdn.staticfile.org/prettify/188.0.0/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "【学习笔记】通过文字检索视频片段：VCED之后端逻辑&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 90,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script defer src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>












<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
