<!DOCTYPE html>
<html lang="zh-CN">





<head><!-- hexo injector head_begin start --><!--Google tag(gtag.js)--><script async src="https://www.googletagmanager.com/gtag/js?id=G-6Q0B58X6TL"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date());gtag("config","G-6Q0B58X6TL");</script><!-- hexo injector head_begin end -->
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="Superlova">
  <meta name="keywords" content="">
  <title>【学习笔记】李宏毅2019ML课程-Note1 - Superlova</title>
  <meta name="google-site-verification" content="CPvPw8mUZw65A1ALJ8uRzsYECq4mXgE4_eCq40VIhPM" />
  <link  rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.12.1/css/all.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/mdbootstrap/4.13.0/css/mdb.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css" />

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link  rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css" />

<link  rel="stylesheet" href="/css/main.css" />


  <link defer rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />


<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="Superlova" type="application/atom+xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Superlova</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">首页</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">归档</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/cover_2.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <p class="mt-3 post-meta">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>
                  星期一, 十月 10日 2022, 8:57 晚上
                </p>
              

              <p class="mt-1">
                
                  
                  <span class="post-meta">
                    <i class="far fa-chart-bar"></i>
                    3.8k 字
                  </span>
                

                
                  
                  <span class="post-meta">
                      <i class="far fa-clock"></i>
                      13 分钟
                  </span>
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  <span id="busuanzi_container_page_pv" class="post-meta" style="display: none">
                    <i class="far fa-eye" aria-hidden="true"></i>
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>
                
              </p>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5 z-depth-3" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p
                class="note note-warning">本文最后更新于：星期三, 十月 12日 2022, 9:44 晚上</p>
            
            <div class="markdown-body">
              <p>李宏毅老师主讲的机器学习MOOC课程的笔记，本篇记录的知识点有：机器学习的概念和分类、利用线性模型解决回归问题以及梯度下降。<br><!--more---></p>
<h3 id="一、机器学习介绍"><a href="#一、机器学习介绍" class="headerlink" title="一、机器学习介绍"></a>一、<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/av59538266">机器学习介绍</a></h3><p>说一下我学这门课的初衷吧。其实机器学习的课程在研究生阶段就已经上过了，但是工作之后才发现有一些基础没搞懂或者已经遗忘，因此在学习新知识时存在障碍。恰逢Datawhale给了这次组队学习的机会，我便想与群友们一起把这门基础课程搞定。</p>
<h4 id="1-概要"><a href="#1-概要" class="headerlink" title="1. 概要"></a>1. 概要</h4><p>本节通俗易懂地介绍了机器学习的概念，介绍了AI的发展历史，以及与传统规则的区别。简单来说，<strong>机器学习</strong>是一种从有限数据中学习规律并对未知数据进行预测的方法。</p>
<p>刚开始讲了比较多的名词和概念。老师最后的图里很好地总结了本次课的内容：</p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/机器学习介绍01.png" srcset="/img/loading.gif" alt></p>
<h4 id="首先，机器学习的过程分成三个步骤："><a href="#首先，机器学习的过程分成三个步骤：" class="headerlink" title="首先，机器学习的过程分成三个步骤："></a>首先，机器学习的过程分成三个步骤：</h4><ol>
<li>根据问题的不同，选择模型（function）；</li>
<li>根据模型的不同，定义能够度量学习效果的损失函数；</li>
<li>从有限数据中持续训练模型，使得损失函数最小。</li>
</ol>
<h4 id="其次，根据学习所需的数据是否存在标签，机器学习可以分成如下几类（图中蓝色框框的部分）："><a href="#其次，根据学习所需的数据是否存在标签，机器学习可以分成如下几类（图中蓝色框框的部分）：" class="headerlink" title="其次，根据学习所需的数据是否存在标签，机器学习可以分成如下几类（图中蓝色框框的部分）："></a>其次，根据学习所需的数据是否存在标签，机器学习可以分成如下几类（图中蓝色框框的部分）：</h4><ol>
<li>监督学习，指学习所需的数据是经过人工标注的；</li>
<li>无监督学习，指学习所需的数据不需人工标注；</li>
<li>其他学习方法，比如半监督学习、迁移学习、强化学习等。</li>
</ol>
<h4 id="在监督学习里，根据想要解决的问题不同，可分为如下几类（图中黄色框框的部分）："><a href="#在监督学习里，根据想要解决的问题不同，可分为如下几类（图中黄色框框的部分）：" class="headerlink" title="在监督学习里，根据想要解决的问题不同，可分为如下几类（图中黄色框框的部分）："></a>在监督学习里，根据想要解决的问题不同，可分为如下几类（图中黄色框框的部分）：</h4><ol>
<li>分类问题，指我们希望模型给出yes或no这样具体的评价；</li>
<li>回归问题，指我们希望模型能够给出一个数值，这个数值的大小有现实意义；</li>
<li>结构化问题，我们希望模型直接输出结构化结果，比如语言翻译模型能够产出一段文本，dall-e能够生成图像，等等。</li>
</ol>
<h4 id="分类问题是比较简单的问题，有很多模型可以解决分类问题（图中绿色框框的部分）："><a href="#分类问题是比较简单的问题，有很多模型可以解决分类问题（图中绿色框框的部分）：" class="headerlink" title="分类问题是比较简单的问题，有很多模型可以解决分类问题（图中绿色框框的部分）："></a>分类问题是比较简单的问题，有很多模型可以解决分类问题（图中绿色框框的部分）：</h4><ol>
<li>线性模型；</li>
<li>非线性模型，比如深度学习、SVM、决策树等方法。</li>
</ol>
<p>后续我们会学到什么是线性模型、什么是非线性模型，以及上面的具体模型的设计细节。</p>
<h4 id="为什么要学习机器学习这门课程？"><a href="#为什么要学习机器学习这门课程？" class="headerlink" title="为什么要学习机器学习这门课程？"></a>为什么要学习机器学习这门课程？</h4><p><del>当然是为了挣钱了</del></p>
<p>由于目前还没有一个普适的学习模型，能够解决世界一切可以用机器学习方法解决的问题，因此，我们需要依赖经验和知识，来根据不同的问题，选择不同的学习模型和和损失函数。还记得机器学习的三个步骤吗？选择模型、定义损失函数、训练模型过程的知识，都是能够帮助我们得到更加可靠的机器学习系统的技能。学习这门课程，能够帮助我们成为一名更好的机器学习工程师。</p>
<h3 id="二、机器学习案例——回归问题"><a href="#二、机器学习案例——回归问题" class="headerlink" title="二、机器学习案例——回归问题"></a>二、<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ht411g7Ef?p=3">机器学习案例——回归问题</a></h3><p>这部分以一个回归问题为引子，引导我们探索机器学习的三大步骤。回归问题比较普遍，像股票预测、温度预测、房价预测等，都是回归问题。</p>
<p>机器学习的三大步骤分别为：</p>
<ol>
<li>根据问题的不同，选择模型（function）；</li>
<li>根据模型的不同，定义能够度量学习效果的损失函数；</li>
<li>从有限数据中持续训练模型，使得损失函数最小。</li>
</ol>
<h4 id="第一步，为回归问题选择合适的模型"><a href="#第一步，为回归问题选择合适的模型" class="headerlink" title="第一步，为回归问题选择合适的模型"></a>第一步，为回归问题选择合适的模型</h4><p>这里我们使用线性模型试试水。所谓<strong>线性模型</strong> (Linear Model) 是把输入数据的各种特征，通过线性组合的方式进行预测。</p>
<script type="math/tex; mode=display">
y=b+\Sigma\omega_{i}x_{i}</script><p>其中y是预测值，x是特征本身，w是特征对应的参数。我们的学习目标就是找到正确的w，令预测值y尽可能靠谱。</p>
<h4 id="第二步，为线性模型选择合适的评估函数"><a href="#第二步，为线性模型选择合适的评估函数" class="headerlink" title="第二步，为线性模型选择合适的评估函数"></a>第二步，为线性模型选择合适的评估函数</h4><p>知错能改，善莫大焉。每当模型预测得到一个值，为了让模型认识到自己的预测值y与真实值$\hat{y}$的差距，我们不妨直接取二者之差，作为计算差距的<strong>损失函数</strong> (Loss Function)。</p>
<script type="math/tex; mode=display">
L(f)=\sum (y-\hat{y})</script><p>这样肯定是有问题的，假设我们有两组数据，一组超过真实值0.5，另一组低于预测值0.5，它们与真实值的差值分别是0.5与-0.5。结果经过我们的计算，损失函数居然为0，也就是没有损失？</p>
<p>为了避免上述情况的出现，我们选择平方损失函数作为衡量差距的手段：</p>
<script type="math/tex; mode=display">
L(f)=\sum (y-\hat{y})^2</script><p>其实也有其他的损失函数定义方法可以规避第一个损失函数的问题，比如使用绝对值。但这里我们就钦定平方损失函数了，它有很多好处，但是我们先按下不表。</p>
<h4 id="第三步，进行训练，并利用损失函数指导训练过程"><a href="#第三步，进行训练，并利用损失函数指导训练过程" class="headerlink" title="第三步，进行训练，并利用损失函数指导训练过程"></a>第三步，进行训练，并利用损失函数指导训练过程</h4><p>到目前为止，我们有很多带标签的数据 $(x,\hat{y})$，有线性模型，有损失函数。那我该怎么得到训练好的模型呢？</p>
<p><strong>最好的模型</strong>到底是什么？对于线性模型来说，其实求解最优的$w$和$b$，从而可以让我们的模型无论输入什么$x$，都能准确得到与真实值相差无几的$y$。</p>
<p>让我们忘掉w和b的具体含义、晦涩不清的L函数，专心解决这个问题：如何优化$w$和$b$，以便L达到最小？</p>
<script type="math/tex; mode=display">
w^*=arg\min_{w}L(w) \\
b^*=arg\min_{b}L(b)</script><p>一种解决问题的方法使用微积分来嗯算，通过计算导数去寻找L的极值点。运气好的话，L的变量不多，该方法看似可行；运气不好的话，我们面对的问题过于复杂、参数过多，问题就不好解决了。</p>
<p>还有一种笨办法是穷举所有可能的$w$，选择能使L最小的$w^*$即可。这种方法虽然可行，但是没有效率。</p>
<p>有一种通用的最优化方法，叫做<strong>梯度下降</strong> (Gradient Descent) 方法，专门用于解决这种凸优化问题。使用梯度下降算法的前提是优化目标是可微的。</p>
<h5 id="1-梯度下降算法简介"><a href="#1-梯度下降算法简介" class="headerlink" title="1. 梯度下降算法简介"></a>1. 梯度下降算法简介</h5><p>恰好，我们的损失函数L是可微的，也就是二阶可导的。如果我们当初选取损失函数时，使用绝对值作为损失函数，处理起来便没有这么便利了。</p>
<p>梯度下降的具体过程是这样的：</p>
<ol>
<li>选择一个初始$w_0$</li>
<li>计算该位置下w对L的微分，这个微分对应函数在此处下降最快的方向；</li>
<li>将$w_0$朝着这个方向移动一小步$ \eta$<script type="math/tex; mode=display">w\prime=w_0-\eta\frac{\mathrm{d}L}{\mathrm{d}w}</script></li>
<li>在新的位置开始新一轮迭代计算，直到$w$不再变化为止。</li>
</ol>
<p>不妨将梯度下降算法的求解过程想象为人下山的过程，人会先找到下山最快的方向，然后朝着那个方向走一步，直到抵达最低点。</p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/模拟梯度下降.png" srcset="/img/loading.gif" alt></p>
<p>在上图中，每一条线围成的圈就是等高线，代表损失函数的值，颜色约深的区域代表的损失函数越小；红色的箭头代表等高线的法线方向。</p>
<p>上述过程是求解L在变量w下的最优解的梯度下降过程，但是L还与偏移量b存在对应关系，所以实际上梯度下降在线性模型的具体公式如下：</p>
<script type="math/tex; mode=display">
w_k\rightarrow w'_k=w_k-\eta\frac{\partial C}{\partial w_k} \\
b_l\rightarrow b'_l=b_l-\eta\frac{\partial C}{\partial b_l}</script><p>其中，偏微分的具体公式如下：</p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/线性回归偏微分方程.png" srcset="/img/loading.gif" alt></p>
<h5 id="2-梯度下降算法的局限性"><a href="#2-梯度下降算法的局限性" class="headerlink" title="2. 梯度下降算法的局限性"></a>2. 梯度下降算法的局限性</h5><p>首先，<strong>梯度下降算法容易陷入局部最优，找不到全局最优解</strong>。</p>
<p>如下图所示，当梯度下降算法优化到local minima 时，前面有座高山，它的梯度是正的，优化算法会强迫我们往回走。</p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/梯度下降算法局部最优.png" srcset="/img/loading.gif" alt></p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/梯度下降局部最优2.png" srcset="/img/loading.gif" alt></p>
<p>这个问题在我们的线性回归模型里暂时遇不到，因为线性模型非常简单，是一个凸函数。但当我们试图利用梯度下降算法训练复杂模型，比如神经网络时，就很有可能遭遇该问题。</p>
<p>有很多方法能够解决梯度下降算法的全局最优解问题，包括调整每次行进的步长$\eta$，使其更有希望跨越“大山”等手段等等。</p>
<p>其次，梯度下降算法要求目标函数是可微的，这在某些情况下会<strong>产生相当大的计算代价</strong>。假设我们的问题有上百万维，计算二阶偏导数就需要上万亿（百万的平方）次！</p>
<p>再次，<strong>当训练数据相当多时，梯度下降算法会变得很慢</strong>。在实践中，为了计算梯度$\nabla L$，我们需要为了每个训练样本x单独计算梯度$\nabla L_x$，然后求平均值。这会花费很长时间。</p>
<h4 id="检验：如何检验模型是否训练成功？更加复杂的模型以及对应的风险。"><a href="#检验：如何检验模型是否训练成功？更加复杂的模型以及对应的风险。" class="headerlink" title="检验：如何检验模型是否训练成功？更加复杂的模型以及对应的风险。"></a>检验：如何检验模型是否训练成功？更加复杂的模型以及对应的风险。</h4><p>经过一轮又一轮的优化，我们终于求得了该问题下线性回归模型的最优参数$w$和$b$。接下来该如何检验模型在未知数据上的泛化能力呢？</p>
<p>我们可以在训练之前，把数据集分成两部分，一部分用作后续的训练，另一部分用作最后的验收。如果在这部分测试数据上的表现与训练过程中的表现一致，那我们就可以验收。</p>
<p>这种通过划分数据集为训练集和测试集的方法，与其说是一种技术细节，不如说是一种工程实践上的经验。通过训练集和测试集的性能比较，我们可以发现模型存在的潜在问题：</p>
<p><strong>1. 训练集和测试集上的表现都不太高；</strong></p>
<p>这种情况我们称之为欠拟合。线性模型由于过于简单，当面对一些较复杂的现实问题时，欠拟合便出现了。你会发现无论如何训练，无论投入多少数据都很难提升模型的性能了。我们需要更加复杂的模型，然后进行上面所说的机器学习三个步骤：选择新模型，选择合适的损失函数，选择优化方法进行训练。</p>
<p>对于一些现实问题，类似$y=wx+b$这种一次模型确实过于简单了。比如预测房价，可能与房屋面积有关，也可以与房屋面积的平方有关，甚至是三次方、四次方。</p>
<p>课堂上老师举了一个例子，用一次函数模型预测宝可梦数据集，效果如下：</p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/宝可梦1.png" srcset="/img/loading.gif" alt></p>
<p>模型在测试集上的误差平均值为 35.0</p>
<p>当我们使用更复杂的2次模型时，模型性能有明显好转：</p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/宝可梦2.png" srcset="/img/loading.gif" alt></p>
<p>模型的图像从一次函数变为二次函数了，更好拟合了训练集和测试集。测试集平均误差降至 18.4 了。那是不是模型越复杂，性能越好呢？</p>
<p><strong>2. 训练集上的表现良好，测试集上的表现很差</strong></p>
<p>当我们持续优化模型复杂度到3次方函数、4次方函数时，测试集平均误差开始停滞，4次方函数的平均误差不降反增：</p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/宝可梦3.png" srcset="/img/loading.gif" alt></p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/宝可梦4.png" srcset="/img/loading.gif" alt></p>
<p>训练集平均误差【15.4】【15.3】【14.9】【12.8】<br>测试集平均误差【18.4】【18.1】【28.8】【232.1】</p>
<p>这种情况称之为过拟合。所谓“过犹不及”，那我们应该怎样选择模型的复杂度，避免过拟合呢？我们可以将模型复杂度与测试集性能之间的关系绘制成图像，通过寻找图像的“拐点”来决定模型的复杂度。</p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/宝可梦性能变化.png" srcset="/img/loading.gif" alt></p>
<h4 id="反思：改进模型性能的其他方法"><a href="#反思：改进模型性能的其他方法" class="headerlink" title="反思：改进模型性能的其他方法"></a>反思：改进模型性能的其他方法</h4><p>上面的宝可梦CP值预测问题，老师之后给出了更多的数据，绘制在坐标图上：</p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/宝可梦5.png" srcset="/img/loading.gif" alt></p>
<p>很显然，任何曲线的线性模型都没办法拟合这种数据点。这是哪里出了问题？答案是我们忽略了数据点的其他特征。当我们引入其他特征到模型后，线性模型的表达能力就增强了。下面就是引入了宝可梦种类的特征：</p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/宝可梦6.png" srcset="/img/loading.gif" alt></p>
<p>但是当我们继续引入一些无关特征，比如宝可梦的性别、年龄等，过拟合现象再次出现：</p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/宝可梦7.png" srcset="/img/loading.gif" alt></p>
<p>这是由于在训练过程中，某些特征的权重过大导致的。一种直观的解释是，模型训练过程也会偷懒！如果数据量不足，模型会自动选取某几个影响力大的特征，赋予较高的权值，然后忽略其他特征，那些被忽略的特征中可能包含更加有用的信息。</p>
<p>我们希望最终得到的模型不要出现太大的权重，为了防止某些特征的权值过大，限制权重的增长速度，可以使用正则化方法。</p>
<p><img src="/2022/10/10/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9D%8E%E5%AE%8F%E6%AF%852019ML%E8%AF%BE%E7%A8%8B-P1/正则化1.png" srcset="/img/loading.gif" alt></p>
<p>改造后的损失函数，末尾添加上了一个正则化项，这个正则化项的大小仅与模型的参数大小有关。参数越大，正则化项越大。有了正则化项，模型在优化过程就会更倾向于选择参数值更小的模型了。</p>
<p>在很多应用场景中，并不是 $w$ 越小模型越平滑越好，但是经验值告诉我们 $w$ 越小大部分情况下都是好的。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol>
<li>机器学习的概念、分类和三个步骤：选择模型、选择损失函数、选择优化方法；</li>
<li>根据三个步骤，实践解决回归问题：使用线性模型，解决宝可梦CP值预测问题；</li>
</ol>
<p>这里的重点是梯度下降算法，后面还会继续学习该算法。</p>
<ol>
<li>通过分析例子的优化点，引出模型常用的优化方法以及风险：过拟合、欠拟合，以及他们的解决方案。</li>
</ol>
<p>过拟合问题的解决方法有：降低模型复杂度、增加训练样本、增加训练样本的特征、添加正则化项等。</p>

            </div>
            <hr>
            <div>
              <p>
                
                  <span>
                <i class="iconfont icon-inbox"></i>
                    
                      <a class="hover-with-bg" href="/categories/notes/">notes</a>
                      &nbsp;
                    
                  </span>&nbsp;&nbsp;
                
                
                  <span>
                <i class="iconfont icon-tag"></i>
                    
                      <a class="hover-with-bg" href="/tags/Machine-Learning/">Machine Learning</a>
                    
                      <a class="hover-with-bg" href="/tags/MOOC/">MOOC</a>
                    
                  </span>
                
              </p>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <script defer src="https://utteranc.es/client.js"
          repo="superlova / superlova.github.io"
          issue-term="pathname"
  
          label="utterances"
    
          theme="github-light"
          crossorigin="anonymous"
  >
  </script>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc-start"></div>
<div id="toc">
  <p class="h5"><i class="far fa-list-alt"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
<div>
  <span id="timeDate">载入天数...</span>
  <span id="times">载入时分秒...</span>
  <script>
  var now = new Date();
  function createtime(){
      var grt= new Date("02/14/2017 00:00:00");//此处修改你的建站时间或者网站上线时间
      now.setTime(now.getTime()+250);
      days = (now - grt ) / 1000 / 60 / 60 / 24;
      dnum = Math.floor(days);
      hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum);
      hnum = Math.floor(hours);
      if(String(hnum).length ==1 ){
          hnum = "0" + hnum;
      }
      minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
      mnum = Math.floor(minutes);
      if(String(mnum).length ==1 ){
                mnum = "0" + mnum;
      }
      seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
      snum = Math.round(seconds);
      if(String(snum).length ==1 ){
                snum = "0" + snum;
      }
      document.getElementById("timeDate").innerHTML = "本站安全运行&nbsp"+dnum+"&nbsp天";
      document.getElementById("times").innerHTML = hnum + "&nbsp小时&nbsp" + mnum + "&nbsp分&nbsp" + snum + "&nbsp秒";
  }
  setInterval("createtime()",250);
  </script>
</div>

<p id="hitokoto">:D 获取中...</p>
<script>
  fetch('https://v1.hitokoto.cn')
    .then(response => response.json())
    .then(data => {
      const hitokoto = document.getElementById('hitokoto')
      hitokoto.innerText = data.hitokoto
      })
      .catch(console.error)
</script>

  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    </div>
    
  <div>
    
      <!-- 不蒜子统计PV -->
      
      <span id="busuanzi_container_site_pv" style="display: none">
      总访问量 <span id="busuanzi_value_site_pv"></span> 次
    </span>
    
    
      <!-- 不蒜子统计UV -->
      
      <span id="busuanzi_container_site_uv" style="display: none">
      总访客数 <span id="busuanzi_value_site_uv"></span> 人
    </span>
    
  </div>


    

    
  </div>
</footer>



<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/popper.js/1.16.1/umd/popper.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="https://cdn.staticfile.org/mdbootstrap/4.13.0/js/mdb.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.10.0/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var navHeight = $('#navbar').height();
      var post = $('#post');
      var toc = $('#toc');
      var tocLimMax = post.offset().top + post.height() - navHeight;

      $(window).scroll(function () {
        var tocLimMin = $('#toc-start').offset().top - navHeight;
        var scroH = document.body.scrollTop + document.documentElement.scrollTop;

        if (tocLimMin <= scroH && scroH <= tocLimMax) {
          toc.css({
            'display': 'block',
            'position': 'fixed',
            'top': navHeight,
          });
        } else if (scroH <= tocLimMin) {
          toc.css({
            'position': '',
            'top': '',
          });
        } else if (scroH > tocLimMax) {
          toc.css('display', 'none');
        }
      });
      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        scrollSmooth: true,
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc > p').css('visibility', 'visible');
      }
      var offset = $('#board-ctn').css('margin-right')
      $('#toc-ctn').css({
        'right': offset
      })
    });
  </script>







  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




<!-- Plugins -->


  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?1040bcc5d25d5f4a9cb5e9855eb2c6db";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  



  <script  src="https://cdn.staticfile.org/prettify/188.0.0/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "【学习笔记】李宏毅2019ML课程-Note1&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 90,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script defer src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>












<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
