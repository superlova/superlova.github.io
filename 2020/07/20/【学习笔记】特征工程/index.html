<!DOCTYPE html>
<html lang="zh-CN">





<head><!-- hexo injector head_begin start --><!--Google tag(gtag.js)--><script async src="https://www.googletagmanager.com/gtag/js?id=G-6Q0B58X6TL"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date());gtag("config","G-6Q0B58X6TL");</script><!-- hexo injector head_begin end -->
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="Superlova">
  <meta name="keywords" content="">
  <title>【学习笔记】特征工程 - Superlova</title>
  <meta name="google-site-verification" content="CPvPw8mUZw65A1ALJ8uRzsYECq4mXgE4_eCq40VIhPM" />
  <link  rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.12.1/css/all.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/mdbootstrap/4.13.0/css/mdb.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css" />

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link  rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css" />

<link  rel="stylesheet" href="/css/main.css" />


  <link defer rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />


<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="Superlova" type="application/atom+xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Superlova</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">首页</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">归档</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/cover_2.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <p class="mt-3 post-meta">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>
                  星期一, 七月 20日 2020, 4:53 下午
                </p>
              

              <p class="mt-1">
                
                  
                  <span class="post-meta">
                    <i class="far fa-chart-bar"></i>
                    4k 字
                  </span>
                

                
                  
                  <span class="post-meta">
                      <i class="far fa-clock"></i>
                      15 分钟
                  </span>
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  <span id="busuanzi_container_page_pv" class="post-meta" style="display: none">
                    <i class="far fa-eye" aria-hidden="true"></i>
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>
                
              </p>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5 z-depth-3" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p
                class="note note-warning">本文最后更新于：星期二, 八月 2日 2022, 9:32 晚上</p>
            
            <div class="markdown-body">
              <p>本文翻译自HJ van Veen的Feature Engineering一文，总结了数据竞赛中常用的特征工程方法。<br><!--more---></p>
<h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><p>本文翻译自HJ van Veen的Feature Engineering一文。由于原文以PPT方式呈现，信息高度压缩，因此在我整理本文过程中，添加了自己的理解。如有错误，敬请指正！</p>
<p><img src="/2020/07/20/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/title.png" srcset="/img/loading.gif" alt></p>
<p><strong>全文概览：</strong></p>
<p><img src="/2020/07/20/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/特征工程.png" srcset="/img/loading.gif" alt></p>
<p>机器学习的特征工程是将原始的输入数据转换成特征，以便于更好的表示潜在的问题、提高预测模型准确性的过程。</p>
<p>特征工程是数据科学中最具创造性的部分，决定了机器学习模型的性能上限。</p>
<p>即便是号称端到端的神经网络也需要特征工程，比如cv需要获得HOG，SIFT，whitening, perturbation, image pyramids, rotation, z-scaling, log-scaling, frame-grams, external semantic data等信息。</p>
<p>机器学习的输入特征包括几种：</p>
<ul>
<li>类别特征：如ID、性别等，值的大小无意义。</li>
<li>数值特征：包括整型、浮点型等，值的大小有意义。</li>
<li>时间特征：如月份、年份、季度、日期、小时等。</li>
<li>空间特征：经纬度等，可以转换成邮编，城市等。</li>
<li>文本特征：文档，自然语言，程序语句等。</li>
</ul>
<h2 id="一、类别特征"><a href="#一、类别特征" class="headerlink" title="一、类别特征"></a>一、类别特征</h2><p>分类特征的特点是几乎总是需要处理后才能输入算法。</p>
<p>类别特征难以估算缺失数据，类别太多（数据维度高）会导致数据稀疏，因此类别特征是特征工程的重点。</p>
<h3 id="One-Hot编码"><a href="#One-Hot编码" class="headerlink" title="One-Hot编码"></a>One-Hot编码</h3><p>将每个特征编码成长度为K的向量，每个向量只有一个维度值为1，其他值为0。这样做的好处是简单易实现，且数据样本的长度也归一化了。</p>
<p>比如分类特征{黄，绿，蓝}可以编码成{001,010,100}；{男，女}=&gt;{01,10}；{1,2,3,4,5,6,7,8,9}=&gt;{000000001,…,100000000}</p>
<p><strong>通常丢弃第一列以避免线性相关。</strong></p>
<p>比如Pandas中，<code>get_dummies</code>函数有一个参数为<code>drop_first</code>，如果为True就丢弃One-Hot编码后数据的第一列，因为丢弃的一列可以通过其他剩余的k-1列计算得到，这一列也就变成了重复数据。</p>
<p>缺陷：容易造成数据稀疏，且现有的One-Hot编码实现方式，较难应对缺失数据和没出现过的变量。</p>
<p>对于类别不多的分类变量，可以采用独热编码。但其实自然语言处理任务中也广泛使用了One-Hot编码。要知道自然语言处理任务的词典大小动辄上万，那么一个单词的One-Hot向量长度也上万，一篇文档转化成One-Hot矩阵，这个数据量就非常可观了。</p>
<h3 id="Hash编码"><a href="#Hash编码" class="headerlink" title="Hash编码"></a>Hash编码</h3><p>无论采用什么编码，只要令每个特征能够独一无二地表示即可。可采用Hash思想。</p>
<p>对于类别数量很多的分类变量，利用哈希函数将一个数据点转换成一个向量。相比较One-Hot模型，哈希编码维度下降了很多。</p>
<p>若采用哈希函数</p>
<pre><code>h(the) mod 5 = 0
h(quick) mod 5 = 1
h(brown) mod 5 = 1
h(fox) mod 5 = 3
</code></pre><p>则对于某句话：<br><code>the quick brown fox</code><br>来说，其使用哈希特转换的向量就是：<br><code>(1,2,0,1,0)</code><br>对比one-hot编码向量（在单词表里就这四个单词的情况下）：<br><code>(0001,0010,0100,1000)</code></p>
<p>哈希表有如下特性：</p>
<ul>
<li>相同的输入可能有相同的输出（一般情况下比例不高）</li>
<li>不同的输出一定对应不同的输入</li>
<li>正向计算很简单，反向计算很困难</li>
<li>根据输入查找输出效率很高</li>
</ul>
<p>本部分参考自 <a target="_blank" rel="noopener" href="https://www.datalearner.com/blog/1051537932880901">https://www.datalearner.com/blog/1051537932880901</a></p>
<h3 id="标签编码"><a href="#标签编码" class="headerlink" title="标签编码"></a>标签编码</h3><p>给予每个类别变量一个独一无二的数字ID。</p>
<p>假如有三种颜色特征：红、黄、蓝，那么你可能想令红=1，黄=2，蓝=3，这就是标签编码。</p>
<p>这种编码对于树算法等非线性算法比较有用，好处是不会升维，坏处是会让机器学习算法误以为颜色存在数值大小关系。</p>
<h3 id="计数编码"><a href="#计数编码" class="headerlink" title="计数编码"></a>计数编码</h3><p>将每个类别的编码定义为其在数据集中出现的次数。比如在数据集中’红’出现了300次，那么’红’的编码就是300。</p>
<p><code>df.groupby([&#39;category&#39;])[&#39;target&#39;].transform(sum)</code><br>这种做法很常见，也很简单。缺点是对异常值敏感，且不同类别出现次数相同时可能引入冲突。</p>
<h3 id="计数排序编码"><a href="#计数排序编码" class="headerlink" title="计数排序编码"></a>计数排序编码</h3><p>根据类别变量在训练集中出现的次数<strong>排序</strong></p>
<p>对异常值不敏感，不会引入冲突。在实际比赛中效果可能出乎意料的好。</p>
<h3 id="Target编码"><a href="#Target编码" class="headerlink" title="Target编码"></a>Target编码</h3><p>将类别变量编码为分类为正的比例，类似于该类别对正类的贡献指数。</p>
<p>比如职业类别特征{‘manager’,’engineer’,’scientist’}在数据集中，但凡scientist都使得target=1，那么scientist就编码成1.00。</p>
<p><img src="/2020/07/20/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/2020-07-20-11-20-25.png" srcset="/img/loading.gif" alt></p>
<h3 id="类别嵌入"><a href="#类别嵌入" class="headerlink" title="类别嵌入"></a>类别嵌入</h3><p>由神经网络得到每个类别的嵌入表达，将特征投影到更高维度的空间。在进行文档分类等，原本具有语义相似性的单词映射之后的向量之间的距离也比较小，进而可以帮助我们进一步进行机器学习的应用，这一点比独热模型好很多。</p>
<p>参考 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1604.06737">https://arxiv.org/abs/1604.06737</a></p>
<p><img src="/2020/07/20/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/2020-07-20-11-21-54.png" srcset="/img/loading.gif" alt></p>
<h3 id="把Nan也当作一个类别"><a href="#把Nan也当作一个类别" class="headerlink" title="把Nan也当作一个类别"></a>把Nan也当作一个类别</h3><p>只在Nan确定有意义时使用。</p>
<h3 id="多元编码"><a href="#多元编码" class="headerlink" title="多元编码"></a>多元编码</h3><p>将两个二元分类变量组合，形成四元向量表示</p>
<p><img src="/2020/07/20/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/2020-07-19-14-09-28.png" srcset="/img/loading.gif" alt></p>
<h3 id="扩张编码"><a href="#扩张编码" class="headerlink" title="扩张编码"></a>扩张编码</h3><p>将一个Feature拆分成多个Feature</p>
<h3 id="合并编码"><a href="#合并编码" class="headerlink" title="合并编码"></a>合并编码</h3><p>将多个Feature合并成一个Feature</p>
<h2 id="二、数值特征"><a href="#二、数值特征" class="headerlink" title="二、数值特征"></a>二、数值特征</h2><h3 id="舍入"><a href="#舍入" class="headerlink" title="舍入"></a>舍入</h3><p>过高的精度有时是噪音。</p>
<p>舍入后的数据可以被当作是类别变量。</p>
<p>舍入前可以log一下，log转换可以将范围很大的值缩小在一定范围内，这对某些异常值的处理也很有效。</p>
<p><img src="http://www.datalearner.com/resources/blog_images/6a4db741-d9bb-4391-8d24-7214ecd07b3b.jpg" srcset="/img/loading.gif" alt></p>
<h3 id="按数值大小分箱（Binning）"><a href="#按数值大小分箱（Binning）" class="headerlink" title="按数值大小分箱（Binning）"></a>按数值大小分箱（Binning）</h3><p>数据分箱是一种将多个或多或少连续值分组为较少数量的“箱(bin)”的方法。通过分箱，数值特征转换成类别特征了。</p>
<p>例如一天24小时可以分成早晨[5,8)，上午[8,11)，中午[11,14)，下午[14,19)，夜晚[10,22)，深夜[19,24)和[24,5)。因为比如中午11点和12点其实没有很大区别，可以使用分箱技巧处理之后可以减少这些“误差”。</p>
<h3 id="特征缩放（Scaling）"><a href="#特征缩放（Scaling）" class="headerlink" title="特征缩放（Scaling）"></a>特征缩放（Scaling）</h3><p>也称为数据标准化。可以将很大范围的数据限定在指定范围内。由于原始数据的值范围变化很大，在一些机器学习算法中，如果没有标准化，目标函数将无法正常工作。</p>
<p>特征缩放方法主要有：</p>
<ul>
<li>转为标准正态</li>
<li>最大最小缩放</li>
<li>对数缩放</li>
<li>开方缩放 root scale</li>
</ul>
<h3 id="估算缺失数据（Imputation）"><a href="#估算缺失数据（Imputation）" class="headerlink" title="估算缺失数据（Imputation）"></a>估算缺失数据（Imputation）</h3><p>由于各种原因，许多真实世界的数据集包含缺失的值，通常编码为空白、NAN或其他占位符。简单删除该条数据项就太可惜了，一个更好的策略是估算缺失的值， 即从数据的已知部分推断它们。</p>
<p>缺失的值可以用提供的常量值来计算，或使用缺失值所在的每一列的统计数据(平均值不如中位数鲁棒)。处理缺失数据的方法还有很多。</p>
<p>sklearn的SimpleImputer类就是用来估算缺失值的。<br><a target="_blank" rel="noopener" href="https://www.studyai.cn/modules/impute.html">https://www.studyai.cn/modules/impute.html</a></p>
<h3 id="特征交叉-feature-interactions"><a href="#特征交叉-feature-interactions" class="headerlink" title="特征交叉(feature interactions)"></a>特征交叉(feature interactions)</h3><p>在回归模型中加入交互项是一种非常常见的处理方式。它可以极大的拓展回归模型对变量之间的依赖的解释。</p>
<p>举个例子：<a target="_blank" rel="noopener" href="https://www.datalearner.com/blog/1051508158689792">来源</a></p>
<p>不同特征之间可能相互影响，比如阳光和土壤质量同时决定树木生长高度，我们可以建模：</p>
<script type="math/tex; mode=display">\text{Tree}=a\times \text{Sun}+b\times \text{Soil}+c</script><p>但是阳光本身也可能影响土壤质量，而我们建立的线性模型事实上是把土壤和阳光当作独立变量的。想要学习线性相关性，我们可以增加一个特征:</p>
<script type="math/tex; mode=display">\text{Tree}=a\cdot\text{Sun}+b\cdot\text{Soil}+c\cdot(\text{Sun}\cdot\text{Soil})+d</script><p>特征交叉的方法有很多，比如不同特征间进行加减乘除、指数操作等。</p>
<h3 id="非线性特征在线性模型中的应用"><a href="#非线性特征在线性模型中的应用" class="headerlink" title="非线性特征在线性模型中的应用"></a>非线性特征在线性模型中的应用</h3><ul>
<li><p>通过多项式核函数(polynomial kernel)和径向基核函数(RBF kernel)将线性不可分的数据映射到高维空间去</p>
</li>
<li><p>Leafcoding（随机森林嵌入）（acebook的gbdt+lr这种思路）</p>
</li>
<li><p>遗传算法（典型代表gplearn）</p>
</li>
<li><p>局部线性嵌入 Locally Linear Embedding，频谱嵌入 Spectral Embedding，t-SNE （降维提取重要特征）</p>
</li>
</ul>
<h3 id="行统计"><a href="#行统计" class="headerlink" title="行统计"></a>行统计</h3><p>统计一行数据中Nan个数、0的个数、负数个数、最大值、最小值、中位数、峰度偏度等</p>
<h2 id="三、时间特征"><a href="#三、时间特征" class="headerlink" title="三、时间特征"></a>三、时间特征</h2><p>时间变量非常容易出错，需要更好的局部验证方案（如回测）</p>
<h3 id="将时间映射成环（周期性变量）"><a href="#将时间映射成环（周期性变量）" class="headerlink" title="将时间映射成环（周期性变量）"></a>将时间映射成环（周期性变量）</h3><p>Turn single features, like day_of_week, into two coordinates on a circle</p>
<p>Ensures that distance between max and min is the same as min and min +1.</p>
<p>含义是指周六和周天，与周天和周一的距离是一样的。</p>
<p>Use for day_of_week, day_of_month, hour_of_day, etc.</p>
<p>就是将大时间项，比如2019年11月11日分解成小时间项的意思。</p>
<h3 id="趋势线"><a href="#趋势线" class="headerlink" title="趋势线"></a>趋势线</h3><p>数据的变化趋势本身也是信息。因此不要使用诸如total_spend这种总结式变量，要有一些中间变量，诸如spend_in_last_week，spend_in_last_month。展现数据趋势，利于模型获取信息。</p>
<h3 id="事件编码"><a href="#事件编码" class="headerlink" title="事件编码"></a>事件编码</h3><p>将某日期与重大节日之间的距离也作为特征，比如法定假日、重大体育赛事、周末、每月的第一个星期六等。</p>
<h2 id="四、空间特征"><a href="#四、空间特征" class="headerlink" title="四、空间特征"></a>四、空间特征</h2><h3 id="将地点视作分类特征"><a href="#将地点视作分类特征" class="headerlink" title="将地点视作分类特征"></a>将地点视作分类特征</h3><ul>
<li>克里金法 Kriging，空间插值方法</li>
<li>K-means 聚类</li>
<li>原始经纬度</li>
<li>将城市转换为经纬度</li>
<li>在街道名称中添加邮政编码</li>
</ul>
<h3 id="将某地点与关键地点之间的距离也作为特征"><a href="#将某地点与关键地点之间的距离也作为特征" class="headerlink" title="将某地点与关键地点之间的距离也作为特征"></a>将某地点与关键地点之间的距离也作为特征</h3><p>诸如大城市、超市等，对你的任务有重要影响的地区。</p>
<h3 id="位置事件数据可以指示可疑行为"><a href="#位置事件数据可以指示可疑行为" class="headerlink" title="位置事件数据可以指示可疑行为"></a>位置事件数据可以指示可疑行为</h3><p>比如同时出现在不同城市的两笔交易、在与住所或送货地址不同的城镇中消费、从不在同一个位置消费。</p>
<h2 id="五、数据探索"><a href="#五、数据探索" class="headerlink" title="五、数据探索"></a>五、数据探索</h2><p>数据探索的目的是提前发现数据的潜在问题，诸如异常值、噪音；然后探索数据的特征工程方法、清洗方法，为数据预处理做准备。</p>
<p>一开始尝试简单统计量：min、max。</p>
<p>Incorporate the target so find correlation between signal.</p>
<p>我的理解是，探索该特征与该数据的label的相关性。</p>
<h3 id="迭代和Debugging"><a href="#迭代和Debugging" class="headerlink" title="迭代和Debugging"></a>迭代和Debugging</h3><p>特征工程是一个迭代的过程，确保你的Pipeline能够快速迭代。</p>
<p>Use sub-linear debugging: Output intermediate information on the process, do spurious logging</p>
<p>使用sub-linear debugging：输出有关过程的中间信息，进行伪记录。</p>
<p>使用一些帮助快速实验的工具。</p>
<p>一鸟在手胜过双鸟在林，想法太多不容易成功。</p>
<h3 id="Label工程"><a href="#Label工程" class="headerlink" title="Label工程"></a>Label工程</h3><p>可以把数据集的标签label给变换一下，当成数据的特征（有点泄漏答案的意思）。</p>
<ul>
<li>log变换：$y\rightarrow\log{(y+1)}$、$\exp{y_{pred}}-1$</li>
<li>平方变换</li>
<li>Box-Cox变换</li>
<li>创建一个评分，用来把二元分类target变成回归问题</li>
<li>训练回归模型，用于预测测试集中不可获取的特征</li>
</ul>
<h2 id="六、文本特征"><a href="#六、文本特征" class="headerlink" title="六、文本特征"></a>六、文本特征</h2><p>与类别特征类似，特征工程手段更为丰富，举例：</p>
<ul>
<li>Lowercasing,</li>
<li>Removing non-alphanumeric,</li>
<li>Repairing,</li>
<li>Encoding punctuation marks,</li>
<li>Tokenizing,</li>
<li>Token-grams,</li>
<li>skipgrams,</li>
<li>char-grams,</li>
<li>Removing stopwords,</li>
<li>Removing rare words</li>
<li>and very common words,</li>
<li>Spelling Correction,</li>
<li>Chopping,</li>
<li>Stemming,</li>
<li>Lemmatization,</li>
<li>Document features,</li>
<li>Entitity Insertion &amp; Extraction</li>
<li>Simplification,</li>
<li>Word2Vec and GloVe / Doc2Vec,</li>
<li>String Similarity,</li>
<li>Reading level,</li>
<li>Nearest Neighbors,</li>
<li>TF-IDF,</li>
<li>BayesSVM, Vectorization, LDA, LSA.</li>
</ul>
<h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><p>从大写字母转换成小写，从unicode转换成ascii，移除非字母字符，修复源文本中的格式问题等。</p>
<h3 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h3><ul>
<li>将句子分成单词token序列，英文可能好做一点，中文之类的语言就需要特定的工具了，比如jieba分词。</li>
<li>将标点符号也硬编码为token，因为标点可能也代表有用的信息。</li>
<li>词袋模型（bag-of-word model）</li>
<li>N元分词：“I like the Beatles” -&gt; [“I like”, “like the”, “the Beatles”]</li>
<li>Skip-grams：“I like Beatles” -&gt; [“I the”, “like Beatles”]</li>
<li>Char-grams：“Beatles” -&gt; [“Bea”, “eat”, “atl”, “tle”, “les”]</li>
<li>Affixes：Same as char-grams, but only the postfixes and prefixe</li>
</ul>
<h3 id="删除词"><a href="#删除词" class="headerlink" title="删除词"></a>删除词</h3><ul>
<li>删除停用词</li>
<li>删除罕见词</li>
<li>删除其他常见词，不能反映特征的词</li>
</ul>
<h3 id="还原词形-root"><a href="#还原词形-root" class="headerlink" title="还原词形 root"></a>还原词形 root</h3><ul>
<li>拼写检查</li>
<li>Chop，只取每个token的前8个字符</li>
<li>Stem，将token缩减为词根形式</li>
<li>Lemmatize，词形还原</li>
</ul>
<h3 id="更多特征"><a href="#更多特征" class="headerlink" title="更多特征"></a>更多特征</h3><ul>
<li>文档特征，诸如统计空格、tab、换行、字符、token出现次数等</li>
<li>添加一些通用的描述，“Microsoft releases Windows” -&gt; “Microsoft (company) releases Windows (application)”</li>
<li>语法分析树 Parse Tree，NLTK工具包有实现</li>
<li>Reading level: Compute the reading level of a document.（国外的阅读分级制度）</li>
</ul>
<h3 id="相似度"><a href="#相似度" class="headerlink" title="相似度"></a>相似度</h3><ul>
<li>token相似度：计算两段文本中相同token数</li>
<li>压缩距离 Compression distance：一段句子是否能被压缩成另外一段</li>
<li>Levenshitein、Hamming、Jaccard距离，用来衡量两个string的距离，计算将该文本转为另一个文本所需的最小操作次数</li>
<li>word2vec、glove：计算两向量的余弦距离</li>
</ul>
<h3 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h3><ul>
<li>Term Frequency: 能够降低长文本造成的bias</li>
<li>Inverse Document Frequency: 降低常用词造成的Bias</li>
<li>TF-IDF: 辨别在document中最重要的token，删除不重要的token；或者用在数据预处理上，可以使维度下降</li>
</ul>
<h3 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h3><ul>
<li>PCA: 将文本压缩到50~100维的向量</li>
<li>SVD: 同上</li>
<li>LDA: 与TF-IDF配套</li>
<li>LSA: 创建主题向量</li>
</ul>
<h3 id="外部模型"><a href="#外部模型" class="headerlink" title="外部模型"></a>外部模型</h3><ul>
<li>感情分析器：获得text的情感倾向</li>
<li>主题模型：使用一个dataset创建主题向量，用于另一个任务</li>
</ul>
<h2 id="七、泄露的特征-黄金特征"><a href="#七、泄露的特征-黄金特征" class="headerlink" title="七、泄露的特征 / 黄金特征"></a>七、泄露的特征 / 黄金特征</h2><p>特征工程能帮助发现泄露的特征，这些特征可能对你帮助很大。</p>
<ul>
<li>比如“逆向”工程：<ul>
<li>用彩虹表破解MD5哈希。<a target="_blank" rel="noopener" href="https://www.cnblogs.com/by-3ks/articles/4137562.html">彩虹表（Rainbow Table）</a>是一种破解哈希算法的技术，可以破解MD5、HASH等多种密码。</li>
<li>利用TF-IDF获得术语频率。</li>
<li>编码样本数据集的顺序。</li>
<li>编码文件创建日期。</li>
</ul>
</li>
<li>比如规则挖掘：<ul>
<li>查找简单的规则（并对它们进行编码）以帮助模型决策。</li>
</ul>
</li>
</ul>
<h2 id="八、案例研究"><a href="#八、案例研究" class="headerlink" title="八、案例研究"></a>八、案例研究</h2><p>Quora重复问题数据集，约440000个问题，将其分成重复问题或非重复问题。作者将自己解决Quora重复问题的过程分享如下：</p>
<ul>
<li>First attempt: 词袋模型+逻辑回归</li>
<li>Second attempt: token之间进行数据的多项式交互</li>
<li>Third attempt: 使用NLTK的SnowballStemmer进行词干提取</li>
<li>Fourth attempt: 使用2-grams分词</li>
<li>Fifth attempt: 添加以下手工构造的特征：<ul>
<li>归一化问答对的长度</li>
<li>归一化问答对的compression距离</li>
<li>计算问答对的词向量之间的余弦距离</li>
<li>Chargram co-occurence between question pairs.</li>
<li>计算word出现次数：which，what，where</li>
</ul>
</li>
<li>还能想到更多的改进方法吗？<ul>
<li>外部或预训练模型？</li>
<li>Search engine models?</li>
<li>Logic based models?</li>
</ul>
</li>
</ul>
<h2 id="九、其他资源参考"><a href="#九、其他资源参考" class="headerlink" title="九、其他资源参考"></a>九、其他资源参考</h2><ul>
<li><strong>Kaggle forums &amp; kernels:</strong> Far0n, KazAnova, Fchollet, Abhishek, Gilberto Titericz, Leustagos, Owen Zhang, Gert Jacobusse …</li>
<li><strong>Introduction:</strong> <a target="_blank" rel="noopener" href="http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/">http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/</a></li>
<li><strong>Books:</strong><ul>
<li>Mastering Feature Engineering (Alice Zheng),</li>
<li>Feature Extraction (Isabelle Guyon et al.)</li>
</ul>
</li>
<li><strong>Blogs:</strong><ul>
<li><a target="_blank" rel="noopener" href="https://smerity.com/articles/2016/architectures_are_the_new_feature_engineering.html">https://smerity.com/articles/2016/architectures_are_the_new_feature_engineering.html</a></li>
<li><a target="_blank" rel="noopener" href="http://hunch.net/~jl/projects/hash_reps/">http://hunch.net/~jl/projects/hash_reps/</a></li>
<li><a target="_blank" rel="noopener" href="https://blogs.technet.microsoft.com/machinelearning/2014/09/24/online-learning-and-sub-linear-debugging/">https://blogs.technet.microsoft.com/machinelearning/2014/09/24/online-learning-and-sub-linear-debugging/</a></li>
<li><a target="_blank" rel="noopener" href="http://blog.kaggle.com/2015/12/03/dato-winners-interview-1st-place-mad-professors/">http://blog.kaggle.com/2015/12/03/dato-winners-interview-1st-place-mad-professors/</a></li>
<li><a target="_blank" rel="noopener" href="http://blog.kaggle.com/2016/08/24/avito-duplicate-ads-detection-winners-interview-1st-place-team-devil-team-stanislav-dmitrii/">http://blog.kaggle.com/2016/08/24/avito-duplicate-ads-detection-winners-interview-1st-place-team-devil-team-stanislav-dmitrii/</a></li>
<li><a target="_blank" rel="noopener" href="http://www.slideshare.net/DataRobot/featurizing-log-data-before-xgboost">http://www.slideshare.net/DataRobot/featurizing-log-data-before-xgboost</a></li>
</ul>
</li>
<li><strong>Data:</strong> <a target="_blank" rel="noopener" href="https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs">https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs</a></li>
<li><strong>Software:</strong> <a target="_blank" rel="noopener" href="https://github.com/trevorstephens/gplearn">https://github.com/trevorstephens/gplearn</a></li>
</ul>

            </div>
            <hr>
            <div>
              <p>
                
                  <span>
                <i class="iconfont icon-inbox"></i>
                    
                      <a class="hover-with-bg" href="/categories/notes/">notes</a>
                      &nbsp;
                    
                      <a class="hover-with-bg" href="/categories/notes/translation/">translation</a>
                      &nbsp;
                    
                      <a class="hover-with-bg" href="/categories/notes/translation/%E8%BD%AC%E8%BD%BD/">转载</a>
                      &nbsp;
                    
                  </span>&nbsp;&nbsp;
                
                
                  <span>
                <i class="iconfont icon-tag"></i>
                    
                      <a class="hover-with-bg" href="/tags/Machine-Learning/">Machine Learning</a>
                    
                      <a class="hover-with-bg" href="/tags/Feature-Engineering/">Feature Engineering</a>
                    
                      <a class="hover-with-bg" href="/tags/Data-Science/">Data Science</a>
                    
                  </span>
                
              </p>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <script defer src="https://utteranc.es/client.js"
          repo="superlova / superlova.github.io"
          issue-term="pathname"
  
          label="utterances"
    
          theme="github-light"
          crossorigin="anonymous"
  >
  </script>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc-start"></div>
<div id="toc">
  <p class="h5"><i class="far fa-list-alt"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
<div>
  <span id="timeDate">载入天数...</span>
  <span id="times">载入时分秒...</span>
  <script>
  var now = new Date();
  function createtime(){
      var grt= new Date("02/14/2017 00:00:00");//此处修改你的建站时间或者网站上线时间
      now.setTime(now.getTime()+250);
      days = (now - grt ) / 1000 / 60 / 60 / 24;
      dnum = Math.floor(days);
      hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum);
      hnum = Math.floor(hours);
      if(String(hnum).length ==1 ){
          hnum = "0" + hnum;
      }
      minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
      mnum = Math.floor(minutes);
      if(String(mnum).length ==1 ){
                mnum = "0" + mnum;
      }
      seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
      snum = Math.round(seconds);
      if(String(snum).length ==1 ){
                snum = "0" + snum;
      }
      document.getElementById("timeDate").innerHTML = "本站安全运行&nbsp"+dnum+"&nbsp天";
      document.getElementById("times").innerHTML = hnum + "&nbsp小时&nbsp" + mnum + "&nbsp分&nbsp" + snum + "&nbsp秒";
  }
  setInterval("createtime()",250);
  </script>
</div>

<p id="hitokoto">:D 获取中...</p>
<script>
  fetch('https://v1.hitokoto.cn')
    .then(response => response.json())
    .then(data => {
      const hitokoto = document.getElementById('hitokoto')
      hitokoto.innerText = data.hitokoto
      })
      .catch(console.error)
</script>

  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    </div>
    
  <div>
    
      <!-- 不蒜子统计PV -->
      
      <span id="busuanzi_container_site_pv" style="display: none">
      总访问量 <span id="busuanzi_value_site_pv"></span> 次
    </span>
    
    
      <!-- 不蒜子统计UV -->
      
      <span id="busuanzi_container_site_uv" style="display: none">
      总访客数 <span id="busuanzi_value_site_uv"></span> 人
    </span>
    
  </div>


    

    
  </div>
</footer>



<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/popper.js/1.16.1/umd/popper.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="https://cdn.staticfile.org/mdbootstrap/4.13.0/js/mdb.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.10.0/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var navHeight = $('#navbar').height();
      var post = $('#post');
      var toc = $('#toc');
      var tocLimMax = post.offset().top + post.height() - navHeight;

      $(window).scroll(function () {
        var tocLimMin = $('#toc-start').offset().top - navHeight;
        var scroH = document.body.scrollTop + document.documentElement.scrollTop;

        if (tocLimMin <= scroH && scroH <= tocLimMax) {
          toc.css({
            'display': 'block',
            'position': 'fixed',
            'top': navHeight,
          });
        } else if (scroH <= tocLimMin) {
          toc.css({
            'position': '',
            'top': '',
          });
        } else if (scroH > tocLimMax) {
          toc.css('display', 'none');
        }
      });
      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        scrollSmooth: true,
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc > p').css('visibility', 'visible');
      }
      var offset = $('#board-ctn').css('margin-right')
      $('#toc-ctn').css({
        'right': offset
      })
    });
  </script>







  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




<!-- Plugins -->


  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?1040bcc5d25d5f4a9cb5e9855eb2c6db";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  



  <script  src="https://cdn.staticfile.org/prettify/188.0.0/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "【学习笔记】特征工程&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 90,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script defer src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>



  

  
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
              processEscapes: true,
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
      });

      MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });

    </script>

    <script  src="https://cdn.staticfile.org/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" ></script>

  










<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
